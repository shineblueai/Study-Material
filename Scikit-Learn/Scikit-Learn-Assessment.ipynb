{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Scikit-Learn — Assessment\n",
    "\n",
    "This assessment aligns with `Scikit-Learn/Scikit-Learn.ipynb`, `Scikit-Learn/PipeLines.ipynb`, and `Scikit-Learn/NLP.ipynb`. It covers preprocessing, model selection, pipelines, metrics, and basic NLP workflows.\n",
    "\n",
    "Total: 25 questions (10 Theory, 8 Fill-in-the-Blanks, 7 Coding). Difficulty: 40% easy, 40% medium, 20% hard.\n"
   ],
   "id": "50fa3ba203bbb3d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Instructions\n",
    "- Answer all questions.\n",
    "- Implement coding tasks using scikit-learn idioms and run the asserts.\n",
    "- Keep function signatures intact.\n",
    "- Solutions are at the bottom.\n"
   ],
   "id": "dc63e95906888907"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "- `Scikit-Learn/Scikit-Learn.ipynb`\n",
    "- `Scikit-Learn/PipeLines.ipynb`\n",
    "- `Scikit-Learn/NLP.ipynb`\n"
   ],
   "id": "a68cbe5c75697daf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part A — Theory (10)\n",
    "1. What is the train/test split and why is it necessary?\n",
    "2. MCQ: Which class performs standardization? (a) `MinMaxScaler` (b) `StandardScaler` (c) `Normalizer` (d) `OneHotEncoder`\n",
    "3. Explain bias-variance tradeoff in the context of model selection.\n",
    "4. What is cross-validation and how does `StratifiedKFold` differ from `KFold`?\n",
    "5. MCQ: Which is a proper way to avoid data leakage? (a) Fit scaler on full data (b) Fit scaler inside Pipeline (c) Scale test separately with its own fit (d) Skip scaling\n",
    "6. What is the purpose of `Pipeline` and `ColumnTransformer`?\n",
    "7. Explain how `GridSearchCV` works and how it integrates with pipelines.\n",
    "8. Describe the difference between `precision`, `recall`, and `f1`.\n",
    "9. MCQ: For text classification, converting raw text to numeric features can be done by (a) `CountVectorizer` (b) `TfidfVectorizer` (c) both (d) neither\n",
    "10. When would you prefer ROC-AUC vs PR-AUC?\n"
   ],
   "id": "2d20ab107d7c7dd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part B — Fill in the Blanks (8)\n",
    "1. To split data reproducibly, pass `__________` to `train_test_split`.\n",
    "2. Standardization transforms to zero mean and unit __________.\n",
    "3. `OneHotEncoder` handles __________ variables.\n",
    "4. In a `Pipeline`, the last step must be an __________.\n",
    "5. Grid search evaluates combinations of hyperparameters using __________ validation.\n",
    "6. `classification_report` includes precision, recall, and __________.\n",
    "7. To select specific columns by name within a transformer, use `ColumnTransformer` with `__________` transformer.\n",
    "8. In NLP, `tf-idf` downweights terms that are very __________ across documents.\n"
   ],
   "id": "9d30965d48363588"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part C — Coding Tasks (7)\n",
    "Implement with scikit-learn. Run asserts.\n",
    "\n",
    "Tasks:\n",
    "1. `make_standard_pipeline()` — returns a `Pipeline` that standardizes numeric features then fits a `LogisticRegression`.\n",
    "2. `train_test_score(clf, X, y, test_size=0.3, seed=0)` — split data, fit, and return test accuracy.\n",
    "3. `grid_search_C_logreg(X, y, Cs=(0.1,1,10))` — pipeline with `StandardScaler`+`LogisticRegression`, grid-search over `C`, return best `C`.\n",
    "4. `text_pipeline_svm()` — returns a `Pipeline` with `TfidfVectorizer` and `LinearSVC`.\n",
    "5. `column_transform_demo(df)` — given a DataFrame with `num1,num2,cat` build a `ColumnTransformer` that scales numeric and one-hot encodes `cat`; return transformed shape.\n",
    "6. `cv_mean_accuracy(clf, X, y, k=5)` — return mean cross-val accuracy.\n",
    "7. `report_metrics(y_true, y_pred)` — return dict with `precision`, `recall`, `f1` (macro).\n"
   ],
   "id": "fc698eeb0e93104a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def make_standard_pipeline():\n",
    "    pipe = Pipeline([\n",
    "        ('sc', StandardScaler()),\n",
    "        ('clf', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "def train_test_score(clf, X, y, test_size=0.3, seed=0):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=seed, stratify=y if np.unique(y).size>1 else None)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    yp = clf.predict(Xte)\n",
    "    return float(accuracy_score(yte, yp))\n",
    "\n",
    "def grid_search_C_logreg(X, y, Cs=(0.1,1,10)):\n",
    "    pipe = Pipeline([\n",
    "        ('sc', StandardScaler()),\n",
    "        ('clf', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    gs = GridSearchCV(pipe, param_grid={'clf__C': list(Cs)}, cv=3)\n",
    "    gs.fit(X, y)\n",
    "    return float(gs.best_params_['clf__C'])\n",
    "\n",
    "def text_pipeline_svm():\n",
    "    return Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('svm', LinearSVC())\n",
    "    ])\n",
    "\n",
    "def column_transform_demo(df: pd.DataFrame):\n",
    "    ct = ColumnTransformer([\n",
    "        ('num', StandardScaler(), ['num1','num2']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['cat'])\n",
    "    ])\n",
    "    out = ct.fit_transform(df)\n",
    "    return tuple(out.shape)\n",
    "\n",
    "def cv_mean_accuracy(clf, X, y, k=5):\n",
    "    scores = cross_val_score(clf, X, y, cv=k)\n",
    "    return float(scores.mean())\n",
    "\n",
    "def report_metrics(y_true, y_pred):\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "    return {'precision': float(p), 'recall': float(r), 'f1': float(f1)}\n"
   ],
   "id": "7ab637335780ca81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Asserts\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "pipe = make_standard_pipeline()\n",
    "acc = cv_mean_accuracy(pipe, X, y, k=3)\n",
    "assert 0.7 <= acc <= 1.0\n",
    "\n",
    "tt_acc = train_test_score(pipe, X, y, 0.2, 0)\n",
    "assert 0.6 <= tt_acc <= 1.0\n",
    "\n",
    "bestC = grid_search_C_logreg(X, y, Cs=(0.01,0.1,1))\n",
    "assert bestC in (0.01, 0.1, 1)\n",
    "\n",
    "tp = text_pipeline_svm()\n",
    "docs = ['cat sat on mat', 'dog chased cat', 'bird flew']\n",
    "labels = [0, 1, 2]\n",
    "tp.fit(docs, labels)\n",
    "assert hasattr(tp, 'predict')\n",
    "\n",
    "df = pd.DataFrame({'num1':[1,2,3], 'num2':[4,5,6], 'cat':['a','b','a']})\n",
    "shape = column_transform_demo(df)\n",
    "assert isinstance(shape, tuple) and len(shape)==2\n",
    "\n",
    "met = report_metrics([0,1,1],[0,1,0])\n",
    "assert set(met.keys()) == {'precision','recall','f1'}\n",
    "\n",
    "print('Scikit-Learn asserts passed ✅')\n"
   ],
   "id": "2a796b02d49b6904"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Solutions\n",
    "\n",
    "### Theory (sample)\n",
    "1. Split ensures evaluation on unseen data to estimate generalization.\n",
    "2. (b) `StandardScaler`\n",
    "3. Bias: underfitting; variance: overfitting — balance via model capacity/regularization.\n",
    "4. Stratified preserves label proportions; KFold does not.\n",
    "5. (b) Fit scalers within a Pipeline so fit occurs only on training folds.\n",
    "6. Compose preprocessing and model, possibly selective per column with `ColumnTransformer`.\n",
    "7. It evaluates parameter grid via CV; with pipelines, grid keys like `step__param` tune steps.\n",
    "8. Precision: purity of positives; recall: coverage of true positives; f1: harmonic mean.\n",
    "9. (c) both\n",
    "10. ROC-AUC for balanced data; PR-AUC for imbalanced positives.\n",
    "\n",
    "### Fill blanks\n",
    "1. `random_state`\n",
    "2. variance\n",
    "3. categorical\n",
    "4. estimator\n",
    "5. cross\n",
    "6. f1-score\n",
    "7. `remainder='passthrough'` or `make_column_selector`\n",
    "8. frequent"
   ],
   "id": "90fe4c1daee8fac0"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
