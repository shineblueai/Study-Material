{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Streamlit LLM Translator ‚Äî Multi‚Äëprovider\n",
    "Translate text between languages using OpenAI, Gemini, Anthropic, Groq, or Hugging Face models with a simple Streamlit UI.\n"
   ],
   "id": "7ee85cc6a0659d8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Installation (commented)",
   "id": "3286dd07e4d7e186"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# !pip install streamlit openai anthropic google-generativeai groq huggingface_hub\n",
   "id": "1e270e3bf63ddfea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports and helpers",
   "id": "a4d2475e0b673177"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "\n",
    "# Provider factories (lazy)\n",
    "def _openai():\n",
    "    from openai import OpenAI\n",
    "    if (k:=st.secrets.get('OPENAI_API_KEY', None) if hasattr(st,'secrets') else None) or os.environ.get('OPENAI_API_KEY'):\n",
    "        os.environ['OPENAI_API_KEY'] = k or os.environ.get('OPENAI_API_KEY','')\n",
    "    return OpenAI()\n",
    "\n",
    "def _gemini(model_name):\n",
    "    import google.generativeai as genai\n",
    "    genai.configure(api_key=st.secrets.get('GEMINI_API_KEY', os.environ.get('GEMINI_API_KEY')))\n",
    "    return genai.GenerativeModel(model_name)\n",
    "\n",
    "def _anthropic():\n",
    "    import anthropic\n",
    "    if (k:=st.secrets.get('ANTHROPIC_API_KEY', None) if hasattr(st,'secrets') else None) or os.environ.get('ANTHROPIC_API_KEY'):\n",
    "        os.environ['ANTHROPIC_API_KEY'] = k or os.environ.get('ANTHROPIC_API_KEY','')\n",
    "    return anthropic.Anthropic()\n",
    "\n",
    "def _groq():\n",
    "    from groq import Groq\n",
    "    return Groq(api_key=st.secrets.get('GROQ_API_KEY', os.environ.get('GROQ_API_KEY')))\n",
    "\n",
    "def _hf():\n",
    "    from huggingface_hub import InferenceClient\n",
    "    return InferenceClient(token=st.secrets.get('HUGGINGFACEHUB_API_TOKEN', os.environ.get('HUGGINGFACEHUB_API_TOKEN')))\n"
   ],
   "id": "f71ca073e9c648d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# UI",
   "id": "21adbc2c911fb7cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "st.set_page_config(page_title=\"LLM Translator\", page_icon=\"üåê\")\n",
    "st.title(\"üåê LLM Translator ‚Äî Multi‚Äëprovider\")\n",
    "\n",
    "with st.sidebar:\n",
    "    provider = st.selectbox(\"Provider\", [\"OpenAI\",\"Gemini\",\"Anthropic\",\"Groq\",\"HuggingFace\"], index=0)\n",
    "    temperature = st.slider(\"temperature\", 0.0, 1.5, 0.3, 0.1)\n",
    "    max_tokens = st.slider(\"max tokens\", 64, 2048, 512, 32)\n",
    "\n",
    "    if provider==\"OpenAI\":\n",
    "        model = st.text_input(\"Model\", value=\"gpt-4o-mini\")\n",
    "    elif provider==\"Gemini\":\n",
    "        model = st.text_input(\"Model\", value=\"gemini-1.5-flash\")\n",
    "    elif provider==\"Anthropic\":\n",
    "        model = st.text_input(\"Model\", value=\"claude-3-5-sonnet-20241022\")\n",
    "    elif provider==\"Groq\":\n",
    "        model = st.text_input(\"Model\", value=\"llama-3.1-8b-instant\")\n",
    "    else:\n",
    "        model = st.text_input(\"Model\", value=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "\n",
    "src = st.selectbox(\"Source language\", [\"auto\",\"English\",\"French\",\"Spanish\",\"German\",\"Hindi\",\"Chinese\",\"Japanese\"])\n",
    "dst = st.selectbox(\"Target language\", [\"English\",\"French\",\"Spanish\",\"German\",\"Hindi\",\"Chinese\",\"Japanese\"]) \n",
    "\n",
    "text = st.text_area(\"Text to translate\", height=160, placeholder=\"Paste text here‚Ä¶\")\n"
   ],
   "id": "d2ac2223d2b36f33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Translate function",
   "id": "74243ddf89d38ef4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def translate(provider, model, src, dst, text):\n",
    "    instruction = f\"Translate the following text from {src} to {dst}. Keep meaning and tone. Only output the translation.\"\n",
    "    if provider==\"OpenAI\":\n",
    "        client = _openai()\n",
    "        msgs = [{\"role\":\"system\",\"content\":instruction},{\"role\":\"user\",\"content\":text}]\n",
    "        out = client.chat.completions.create(model=model, messages=msgs, temperature=temperature, max_tokens=max_tokens)\n",
    "        return out.choices[0].message.content\n",
    "    if provider==\"Gemini\":\n",
    "        g = _gemini(model)\n",
    "        resp = g.generate_content(f\"{instruction}\\n\\n{text}\")\n",
    "        return getattr(resp,'text',str(resp))\n",
    "    if provider==\"Anthropic\":\n",
    "        a = _anthropic()\n",
    "        resp = a.messages.create(model=model, max_tokens=max_tokens, temperature=temperature,\n",
    "                                 system=instruction, messages=[{\"role\":\"user\",\"content\":text}])\n",
    "        return resp.content[0].text\n",
    "    if provider==\"Groq\":\n",
    "        gq = _groq()\n",
    "        msgs = [{\"role\":\"system\",\"content\":instruction},{\"role\":\"user\",\"content\":text}]\n",
    "        resp = gq.chat.completions.create(model=model, messages=msgs, temperature=temperature, max_tokens=max_tokens)\n",
    "        return resp.choices[0].message.content\n",
    "    if provider==\"HuggingFace\":\n",
    "        hf = _hf()\n",
    "        try:\n",
    "            msgs = [{\"role\":\"system\",\"content\":instruction},{\"role\":\"user\",\"content\":text}]\n",
    "            resp = hf.chat_completion(model=model, messages=msgs, max_tokens=max_tokens, temperature=temperature)\n",
    "            return resp.choices[0].message['content'] if hasattr(resp.choices[0],'message') else resp.choices[0]['message']['content']\n",
    "        except Exception:\n",
    "            prompt = f\"{instruction}\\n\\n{text}\"\n",
    "            return hf.text_generation(model=model, inputs=prompt, max_new_tokens=max_tokens, temperature=temperature)\n",
    "    raise ValueError(\"Unsupported provider\")\n"
   ],
   "id": "6de7278dcd22baf6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run",
   "id": "5c4325fed169b14f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if st.button(\"Translate\", type=\"primary\") and text.strip():\n",
    "    try:\n",
    "        out = translate(provider, model, src, dst, text)\n",
    "    except Exception as e:\n",
    "        out = f\"Error: {e}\"\n",
    "    st.subheader(\"Translation\")\n",
    "    st.code(out)\n"
   ],
   "id": "f6604e9d896d9de0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notes\n",
    "# - For Hugging Face, you can also select specialized translation models per language pair.\n",
    "# - For bulk translation, paste multiple lines; you can add splitting and CSV download easily."
   ],
   "id": "ac4723aeda88fa8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "767e6a459d582645"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
