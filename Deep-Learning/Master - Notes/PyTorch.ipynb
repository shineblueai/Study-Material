{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PyTorch Commands — One command per code cell with purpose\n",
    "This notebook-style script lists commonly used PyTorch commands. Each code cell contains one primary command with an inline comment describing its purpose. Examples are tiny and safe to run. File/network I/O and heavy downloads are commented.\n"
   ],
   "id": "416ea91e46747dd0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Installation (commented) — run in your environment if needed",
   "id": "e57fc5ed2671e8f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# !pip install torch torchvision torchaudio torchmetrics  # install core PyTorch and extras (commented)\n",
   "id": "44f01beb2ff9b6ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports and version/device info",
   "id": "4e9be79567b9f85d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import torch  # main PyTorch import\n",
   "id": "3cae480964685e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.__version__  # show PyTorch version\n",
   "id": "eb95bdd362d4299d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.cuda.is_available()  # check if CUDA GPU is available\n",
   "id": "f28f427cb9e4bad2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False  # check Apple MPS (Metal) availability\n",
   "id": "32fb0fa989a0ce0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.manual_seed(42)  # set global random seed for reproducibility (CPU and some CUDA ops)\n",
   "id": "628ed32ee3f93bea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Device selection and transfer",
   "id": "666f25d6e5a7bf7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else ('mps' if getattr(torch.backends, 'mps', None) and torch.backends.mps.is_available() else 'cpu'))  # choose best available device\n",
   "id": "f7588e1f30b4bca4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.tensor([1.0, 2.0]).to(device)  # move a tensor to the selected device\n",
   "id": "2aad300dfff4ebd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tensors: creation and properties",
   "id": "7044991fc78f8ad3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.tensor([[1, 2], [3, 4]], dtype=torch.int32)  # create a tensor from data with explicit dtype\n",
   "id": "ee246f6a94a92b5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.zeros((2, 3))  # tensor of zeros with given shape\n",
   "id": "829b0e5f9f0a4cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.ones(3, 2)  # tensor of ones with given shape (varargs shape)\n",
   "id": "44e4a5fcba6217bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.full((2, 2), fill_value=7)  # tensor filled with a scalar value\n",
   "id": "d1f4671aaf3d35ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.arange(0, 10, 2)  # integer range with step\n",
   "id": "bafaaf436e0bbd6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.linspace(0.0, 1.0, steps=5)  # evenly spaced numbers over an interval\n",
   "id": "dba7d8b97a83358b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.eye(4)  # identity matrix\n",
   "id": "23d6cfe22c1199ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.rand((2, 3), generator=torch.Generator().manual_seed(42))  # random uniform values in [0,1)\n",
   "id": "cf88a8e854da6eec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.randn((2, 3), generator=torch.Generator().manual_seed(42))  # random normal values\n",
   "id": "f7230927403d7f72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.randint(low=0, high=10, size=(2, 3))  # random integers in [low, high)\n",
   "id": "de3244d50bb0c727"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.tensor([1, 0, 1]).to(torch.float32)  # cast tensor to a different dtype\n",
   "id": "888111460aa1766c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.tensor([[1, 2], [3, 4]]).shape  # tensor shape\n",
   "id": "485ff59c8d72dcf7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.tensor([[1, 2], [3, 4]]).ndim  # tensor rank (number of dimensions)\n",
   "id": "517b2ac6d4f9f7f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reshape, transpose, concatenate, stack, squeeze/unsqueeze",
   "id": "9a5937221205e2ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.arange(6).reshape(2, 3)  # reshape tensor to a new shape\n",
   "id": "d4471ce7107d9604"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.arange(6).reshape(2, 3).T  # transpose (swap last two axes for 2D)\n",
   "id": "c85ce8aee3d1adad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.cat([torch.ones(2, 2), torch.zeros(2, 2)], dim=0)  # concatenate tensors along a dimension\n",
   "id": "b3bd2562f207bacd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.stack([torch.arange(3), torch.arange(3)], dim=1)  # stack tensors along a new dimension\n",
   "id": "1778b0ec13f96247"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.arange(3).unsqueeze(0)  # add a new dimension at the given axis\n",
   "id": "9f55489f177971a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.zeros(1, 3, 1).squeeze(dim=(0, 2))  # remove dimensions of size 1\n",
   "id": "cd82eb2b76ab367"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Indexing, slicing, gathering, masking",
   "id": "c489039effa040de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.tensor([[10, 11, 12], [13, 14, 15]])[0]  # basic indexing (first row)\n",
   "id": "c55ff9c528f29f20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.tensor([[10, 11, 12], [13, 14, 15]])[:, 1:]  # slice rows/cols using Python slices\n",
   "id": "8d2d6df8eead34e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.gather(torch.tensor([[1, 2, 3], [4, 5, 6]]), dim=1, index=torch.tensor([[0, 2, 1], [2, 1, 0]]))  # gather elements by index\n",
   "id": "bffa955427706fe1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.tensor([10, 20, 30, 40])[torch.tensor([True, False, True, False])]  # boolean mask selection\n",
   "id": "c8342a63985fd5e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Broadcasting and elementwise math",
   "id": "714d09b848b559ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.ones(2, 3) + 2  # scalar-tensor broadcasting (add 2 to all elements)\n",
   "id": "284fcadedb959072"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.ones(2, 3) + torch.tensor([1.0, 2.0, 3.0]).unsqueeze(0)  # row-wise broadcasting\n",
   "id": "fc5b53589e38cf89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.add(torch.tensor([1, 2]), torch.tensor([3, 4]))  # elementwise addition\n",
   "id": "e3aeb9c2f47b8cc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.mul(torch.tensor([2, 3]), torch.tensor([4, 5]))  # elementwise multiplication\n",
   "id": "9e9abf66d172e5d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.div(torch.tensor([10.0, 20.0]), torch.tensor([2.0, 5.0]))  # elementwise division\n",
   "id": "357e15ee8d59d422"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.pow(torch.tensor([2.0, 3.0]), 2.0)  # elementwise power\n",
   "id": "88b813816e427e7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.sqrt(torch.tensor([4.0, 9.0]))  # elementwise square root\n",
   "id": "adf843e09a812aa4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reductions and linear algebra",
   "id": "b62c3d356a016bf3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.sum(torch.arange(6))  # sum of all elements\n",
   "id": "4a295b3e8b6e860"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.mean(torch.tensor([1.0, 2.0, 3.0]))  # mean of elements\n",
   "id": "452749b86afb8ce3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.max(torch.tensor([[1, 8], [3, 4]]), dim=0).values  # max along a dimension\n",
   "id": "d1b4593108cd6431"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.matmul(torch.arange(6, dtype=torch.float32).reshape(2, 3), torch.ones(3, 2))  # matrix multiplication\n",
   "id": "dd3ae4ff91c2f571"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.einsum('ij,jk->ik', torch.ones(2, 3), torch.ones(3, 4))  # Einstein summation for flexible tensor ops\n",
   "id": "7080ff7c1981d72a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.linalg.norm(torch.tensor([[3.0, 4.0]]))  # L2 norm of a tensor\n",
   "id": "bf52180aa4dd30f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.topk(torch.tensor([0.2, 0.5, 0.1, 0.8]), k=2)  # top-k values and indices\n",
   "id": "92c740d884b365ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.nn.functional.softmax(torch.tensor([2.0, 1.0, 0.1]), dim=-1)  # softmax over last dimension\n",
   "id": "ca7dff815b7ab4da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.nn.functional.log_softmax(torch.tensor([2.0, 1.0, 0.1]), dim=-1)  # log-softmax for numerical stability\n",
   "id": "dccd2db6d2095b68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Autograd: gradients and graph control",
   "id": "4bf2492e4ac6849f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x = torch.tensor(3.0, requires_grad=True)  # create a leaf tensor that tracks gradients\n",
   "id": "756de8c37f2c0012"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y = x**2 + 2*x + 1; y.backward(); x.grad  # compute dy/dx at current x via backward\n",
   "id": "d8d26981e6a03030"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "with torch.no_grad(): torch.tensor([1.0, 2.0]) * 2  # disable autograd for inference to save memory\n",
   "id": "b425212d6c2daed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.tensor([1.0, 2.0], requires_grad=True).detach()  # detach tensor from graph (no gradients)\n",
   "id": "71fd1685c2a060ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom autograd Function (advanced)",
   "id": "527d2fe7d5bb77ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ClampGradFn(torch.autograd.Function):  # define a custom op with custom backward\n",
    "    @staticmethod\n",
    "    def forward(ctx, inp): ctx.save_for_backward(inp); return inp\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out): return grad_out.clamp(-1.0, 1.0)\n",
    "ClampGradFn.apply(torch.tensor(10.0, requires_grad=True))  # apply custom function (gradient will be clamped)\n"
   ],
   "id": "82c7773dd4032a68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# torch.nn: layers, activations, losses",
   "id": "71c527822782fd34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import torch.nn as nn  # neural network module (layers, losses, activations)\n",
   "id": "c79c333f79874798"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.Linear(4, 2)  # fully connected (dense) layer\n",
   "id": "fd1b55a371c54249"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.ReLU()  # ReLU activation function\n",
   "id": "58962a79ae466369"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.Sigmoid()  # sigmoid activation function\n",
   "id": "261ebb4b323cd452"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.Softmax(dim=-1)  # softmax module over a dimension\n",
   "id": "b0d2b9f149fda956"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, padding=1)  # 2D convolution layer for images\n",
   "id": "3064b33382cea2a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.MaxPool2d(kernel_size=2, stride=2)  # 2D max pooling layer\n",
   "id": "1bea22a57b5071fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.Flatten()  # flatten layer to vectorize features\n",
   "id": "8cb96cfd433db190"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.Embedding(num_embeddings=5000, embedding_dim=64)  # embedding layer for token ids\n",
   "id": "c59f762ff75d0fcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.LSTM(input_size=16, hidden_size=32, batch_first=True)  # LSTM layer for sequences\n",
   "id": "d28819cb5e9595a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.GRU(input_size=16, hidden_size=32, batch_first=True)  # GRU layer for sequences\n",
   "id": "480b2c858b4463f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.BatchNorm1d(num_features=8)  # batch normalization for 1D features\n",
   "id": "de752268f1cd3ce3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.Dropout(p=0.5)  # dropout regularization layer\n",
   "id": "55f0cd06f982c1ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.CrossEntropyLoss()  # classification loss (logits -> softmax inside)\n",
   "id": "6bf326750f324259"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.MSELoss()  # mean squared error loss for regression\n",
   "id": "2a8adaa1ee4da706"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Building a tiny model and running a forward pass",
   "id": "d0efa8e73e721abf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = nn.Sequential(nn.Linear(10, 32), nn.ReLU(), nn.Linear(32, 2))  # small MLP model for demo\n",
   "id": "f23c2a8b598ffa53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model(torch.randn(4, 10))  # forward pass on a small batch (4 samples, 10 features)\n",
   "id": "ec094fc14a057799"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optimizers and learning-rate schedulers",
   "id": "4547d0dedba68494"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optim = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-2)  # Adam optimizer with weight decay\n",
   "id": "2cf4c07de8a51d5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)  # SGD optimizer with momentum\n",
   "id": "517e4bc217de7c53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sched = torch.optim.lr_scheduler.StepLR(optim, step_size=10, gamma=0.1)  # step-wise LR decay scheduler\n",
   "id": "f866bcbeb354347d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=50)  # cosine annealing LR scheduler\n",
   "id": "b5d83a048d76023b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optim.zero_grad(set_to_none=True)  # reset gradients before backward pass (optional memory optimization)\n",
   "id": "dc85069435d8a6ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# One training step pattern (tiny synthetic example)",
   "id": "2550d1ae8193ff1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_demo = torch.randn(16, 10); y_demo = torch.randint(0, 2, (16,))  # synthetic mini-batch (features and integer labels)\n",
   "id": "58359dc11653e3f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "crit = nn.CrossEntropyLoss()  # choose loss function for classification\n",
   "id": "6c8816a0cec8ac8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logits = model(X_demo); loss = crit(logits, y_demo); loss.backward(); optim.step(); sched.step()  # basic train step: forward -> loss -> backward -> update -> schedule\n",
   "id": "f6d7e52086e5b2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Automatic Mixed Precision (AMP) for faster training on GPUs",
   "id": "d6f178712266ed74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())  # gradient scaler for AMP (enabled on CUDA)\n",
   "id": "4fd35d331483ddb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()): _ = model(torch.randn(4, 10, device=device))  # autocast forward pass for mixed precision\n",
   "id": "b83e592d1894ff5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data utilities: Dataset and DataLoader",
   "id": "33cb320a0938679c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split  # dataset and loader utilities\n",
   "id": "a7fbf2a536de3ae1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "TensorDataset(torch.randn(5, 3), torch.randint(0, 2, (5,)))  # simple dataset from tensors (features, labels)\n",
   "id": "84c637bb13078cae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ToyDataset(Dataset):  # minimal custom dataset example\n",
    "    def __init__(self, n=20): self.X = torch.randn(n, 3); self.y = (self.X.sum(dim=1) > 0).long()\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "ToyDataset(n=10)  # instantiate the custom dataset\n"
   ],
   "id": "927ca99f09ecb160"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "DataLoader(ToyDataset(32), batch_size=8, shuffle=True)  # create a data loader for batching and shuffling\n",
   "id": "76fa0a4b9106c48d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_set, val_set = random_split(ToyDataset(50), [40, 10], generator=torch.Generator().manual_seed(42))  # split dataset into train/val subsets\n",
   "id": "a9c5029708e5ccc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Samplers and collate functions",
   "id": "de20c722d864af37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from torch.utils.data import RandomSampler, SequentialSampler  # sampling strategies for DataLoader\n",
   "id": "a88f7045a1f6fcba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "RandomSampler(ToyDataset(10))  # random sampler (permutes indices each epoch)\n",
   "id": "c3f6959cfbd7ae2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "SequentialSampler(ToyDataset(10))  # sequential sampler (ordered indices)\n",
   "id": "56985c30ae2830ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "def simple_collate(batch): xs, ys = zip(*batch); return torch.stack(xs), torch.tensor(ys)  # custom collate function to merge items into a batch\n",
   "id": "a1640ca20777312c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "DataLoader(ToyDataset(8), batch_size=4, collate_fn=simple_collate)  # DataLoader using a custom collate function\n",
   "id": "c1ac142db1ddc8a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# torchvision datasets and transforms (commented to avoid downloads)",
   "id": "5d927f9724454562"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import torchvision\n",
    "# from torchvision import datasets, transforms\n",
    "# transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])  # image transforms pipeline (commented)\n"
   ],
   "id": "ae9ace637c3fe2d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())  # download MNIST (commented)\n",
   "id": "6ccff5b95beffb72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training loop pattern (mini demo on synthetic data)",
   "id": "e8696a17477dbcbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_one_epoch(model, loader, optim, crit, device='cpu'):  # typical training loop over a DataLoader\n",
    "    model.train(); total = 0.0\n",
    "    for Xb, yb in loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        out = model(Xb)\n",
    "        loss = crit(out, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optim.step()\n",
    "        total += loss.item()\n",
    "    return total / max(1, len(loader))\n",
    "train_loader = DataLoader(ToyDataset(64), batch_size=16, shuffle=True)  # small loader for demo\n"
   ],
   "id": "581117f8f9c387fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_one_epoch(model, train_loader, optim, crit, device=device)  # run one small training epoch (on synthetic data)\n",
   "id": "7f567a10c8b48ce0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation pattern (no grad)",
   "id": "52dcd5e0530f5321"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate(model, loader, device='cpu'):  # evaluation loop without gradient tracking\n",
    "    model.eval(); correct = 0; total = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            pred = model(Xb).argmax(dim=1)\n",
    "            correct += (pred == yb).sum().item(); total += yb.numel()\n",
    "    return correct / max(1, total)\n",
    "val_loader = DataLoader(ToyDataset(64), batch_size=32)  # small validation loader\n"
   ],
   "id": "9b143a76adba97e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "evaluate(model, val_loader, device=device)  # compute accuracy over validation set (synthetic)\n",
   "id": "6b0a39862dcbd30c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Saving and loading state (commented paths to avoid I/O)",
   "id": "cee30719c27f9389"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# torch.save(model.state_dict(), 'model.pt')  # save model parameters to disk (commented)\n",
   "id": "a20f2cd9227fb323"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# model.load_state_dict(torch.load('model.pt', map_location='cpu'))  # load parameters from disk (commented)\n",
   "id": "1683b3a83fc2112d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TorchScript: tracing and scripting",
   "id": "9eca88a3f5048895"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "traced = torch.jit.trace(model, torch.randn(1, 10))  # create a TorchScript by tracing a sample input\n",
   "id": "b9eb86dea54be343"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@torch.jit.script\n",
    "def scripted_relu(x: torch.Tensor) -> torch.Tensor:  # compile a function to TorchScript via scripting\n",
    "    return torch.relu(x)\n",
    "scripted_relu(torch.randn(3))  # run scripted function\n"
   ],
   "id": "3d4edad5053acde9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Distributed and parallel training stubs",
   "id": "58493792e634c78c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nn.DataParallel(model)  # simple multi-GPU data-parallel wrapper (useful for quick multi-GPU on single node)\n",
   "id": "a383519be16d990f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # DistributedDataParallel requires torchrun/launch; example command (commented):\n",
    "# # torchrun --nproc_per_node=2 train.py  # launch 2 processes for DDP on one node\n"
   ],
   "id": "8bfc33739dee93ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utilities and helpers",
   "id": "45666a7e8ddfd17a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.cuda.memory_allocated() if torch.cuda.is_available() else 0  # query current GPU memory allocated (bytes)\n",
   "id": "db04fe163afc3d16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.set_float32_matmul_precision('high') if torch.cuda.is_available() else None  # allow TF32/precision tweak on GPUs (if supported)\n",
   "id": "8fa6446f67d37786"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TorchText and TorchAudio stubs (commented)",
   "id": "80bbd651dbc6a416"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import torchtext\n",
    "# from torchtext.data.utils import get_tokenizer  # tokenization utilities (commented)\n"
   ],
   "id": "c84fb1cd395dca44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import torchaudio\n",
    "# wave, sr = torchaudio.functional.resample(torch.randn(1, 16000), 16000, 8000)  # audio resampling (commented)\n"
   ],
   "id": "8a41bb37ef7ca7ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Metrics (torchmetrics stub)",
   "id": "f058b0ebb06d5df9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from torchmetrics.classification import MulticlassAccuracy\n",
    "# MulticlassAccuracy(num_classes=2)(torch.tensor([0,1,1]), torch.tensor([0,1,0]))  # compute accuracy (commented)\n"
   ],
   "id": "f5a3dd1824ded28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notes\n",
    "# 1. Commands that require downloads (datasets, pretrained weights) or file I/O are commented to keep this script safe.\n",
    "# 2. Prefer using GPU if available; AMP (autocast + GradScaler) can speed up training on modern GPUs.\n",
    "# 3. For larger projects, consider higher-level libraries like PyTorch Lightning for boilerplate reduction.\n",
    "# 4. Seed all relevant RNGs (Python, NumPy, PyTorch) for reproducibility in experiments."
   ],
   "id": "649fa3435297962d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6eeaa40638699c49"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
